{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Review Sentiment Analysis\n",
    "\n",
    "This project creates a model used to predict whether an Amazon review is helpful based on the words in the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods/Libraries Used\n",
    "\n",
    "* gzip to extract data from .gz Amazon file\n",
    "* Pandas to see/transform the data\n",
    "* NLTK to remove stopwords from reviews\n",
    "* Scikit-learn's CountVectorizer to create a bag of words model used for the decision trees\n",
    "* Scikit-learn's RandomForestClassifier to create the prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the data into a dataframe\n",
    "Note: Data is located here http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "Use gzip and pandas to get a dataframe of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Taken from Julian McAuley: http://jmcauley.ucsd.edu/data/amazon/\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('health_and_personal.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(346355, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC5GH8CAMAI7</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AnnN</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>01 5, 2011</td>\n",
       "      <td>Handy little gadget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHKSURW85PJUE</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AZ buyer \"AZ buyer\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1329523200</td>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "      <td>4</td>\n",
       "      <td>02 18, 2012</td>\n",
       "      <td>Small &amp; may need to encourage battery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38RMU1Y5TDP9</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Bob Tobias \"Robert Tobias\"</td>\n",
       "      <td>[75, 77]</td>\n",
       "      <td>1275955200</td>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "      <td>4</td>\n",
       "      <td>06 8, 2010</td>\n",
       "      <td>Very good but not great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1XZUG7DFXXOS4</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cat lover</td>\n",
       "      <td>[56, 60]</td>\n",
       "      <td>1202428800</td>\n",
       "      <td>Love the Great point light pocket magnifier!  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>02 8, 2008</td>\n",
       "      <td>great addition to your purse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1MS3M7M7AM13X</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cricketoes</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1313452800</td>\n",
       "      <td>This is very nice. You pull out on the magnifi...</td>\n",
       "      <td>5</td>\n",
       "      <td>08 16, 2011</td>\n",
       "      <td>Very nice and convenient.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                reviewerName   helpful  \\\n",
       "0   ALC5GH8CAMAI7  159985130X                        AnnN    [1, 1]   \n",
       "1   AHKSURW85PJUE  159985130X         AZ buyer \"AZ buyer\"    [1, 1]   \n",
       "2   A38RMU1Y5TDP9  159985130X  Bob Tobias \"Robert Tobias\"  [75, 77]   \n",
       "3  A1XZUG7DFXXOS4  159985130X                   Cat lover  [56, 60]   \n",
       "4  A1MS3M7M7AM13X  159985130X                  Cricketoes    [1, 1]   \n",
       "\n",
       "   unixReviewTime                                         reviewText  overall  \\\n",
       "0      1294185600  This is a great little gadget to have around. ...        5   \n",
       "1      1329523200  I would recommend this for a travel magnifier ...        4   \n",
       "2      1275955200  What I liked was the quality of the lens and t...        4   \n",
       "3      1202428800  Love the Great point light pocket magnifier!  ...        4   \n",
       "4      1313452800  This is very nice. You pull out on the magnifi...        5   \n",
       "\n",
       "    reviewTime                                summary  \n",
       "0   01 5, 2011                    Handy little gadget  \n",
       "1  02 18, 2012  Small & may need to encourage battery  \n",
       "2   06 8, 2010                Very good but not great  \n",
       "3   02 8, 2008           great addition to your purse  \n",
       "4  08 16, 2011              Very nice and convenient.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create missing columns\n",
    "In order to determine if a review is helpful, the ratio of the helpful to unhelpful counts for each review needs to be calculated. That is done by dividing helpful votes/unhelpful votes, but that data is stored in one column, so new columns needs to be created from the exisiting 'helpful' column. A simple for loop and lists are used to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpUp</th>\n",
       "      <th>helpDown</th>\n",
       "      <th>hRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC5GH8CAMAI7</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AnnN</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>This is a great little gadget to have around. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>01 5, 2011</td>\n",
       "      <td>Handy little gadget</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHKSURW85PJUE</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>AZ buyer \"AZ buyer\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1329523200</td>\n",
       "      <td>I would recommend this for a travel magnifier ...</td>\n",
       "      <td>4</td>\n",
       "      <td>02 18, 2012</td>\n",
       "      <td>Small &amp; may need to encourage battery</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A38RMU1Y5TDP9</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Bob Tobias \"Robert Tobias\"</td>\n",
       "      <td>[75, 77]</td>\n",
       "      <td>1275955200</td>\n",
       "      <td>What I liked was the quality of the lens and t...</td>\n",
       "      <td>4</td>\n",
       "      <td>06 8, 2010</td>\n",
       "      <td>Very good but not great</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>0.974026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1XZUG7DFXXOS4</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cat lover</td>\n",
       "      <td>[56, 60]</td>\n",
       "      <td>1202428800</td>\n",
       "      <td>Love the Great point light pocket magnifier!  ...</td>\n",
       "      <td>4</td>\n",
       "      <td>02 8, 2008</td>\n",
       "      <td>great addition to your purse</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1MS3M7M7AM13X</td>\n",
       "      <td>159985130X</td>\n",
       "      <td>Cricketoes</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>1313452800</td>\n",
       "      <td>This is very nice. You pull out on the magnifi...</td>\n",
       "      <td>5</td>\n",
       "      <td>08 16, 2011</td>\n",
       "      <td>Very nice and convenient.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                reviewerName   helpful  \\\n",
       "0   ALC5GH8CAMAI7  159985130X                        AnnN    [1, 1]   \n",
       "1   AHKSURW85PJUE  159985130X         AZ buyer \"AZ buyer\"    [1, 1]   \n",
       "2   A38RMU1Y5TDP9  159985130X  Bob Tobias \"Robert Tobias\"  [75, 77]   \n",
       "3  A1XZUG7DFXXOS4  159985130X                   Cat lover  [56, 60]   \n",
       "4  A1MS3M7M7AM13X  159985130X                  Cricketoes    [1, 1]   \n",
       "\n",
       "   unixReviewTime                                         reviewText  overall  \\\n",
       "0      1294185600  This is a great little gadget to have around. ...        5   \n",
       "1      1329523200  I would recommend this for a travel magnifier ...        4   \n",
       "2      1275955200  What I liked was the quality of the lens and t...        4   \n",
       "3      1202428800  Love the Great point light pocket magnifier!  ...        4   \n",
       "4      1313452800  This is very nice. You pull out on the magnifi...        5   \n",
       "\n",
       "    reviewTime                                summary  helpUp  helpDown  \\\n",
       "0   01 5, 2011                    Handy little gadget       1         1   \n",
       "1  02 18, 2012  Small & may need to encourage battery       1         1   \n",
       "2   06 8, 2010                Very good but not great      75        77   \n",
       "3   02 8, 2008           great addition to your purse      56        60   \n",
       "4  08 16, 2011              Very nice and convenient.       1         1   \n",
       "\n",
       "     hRatio  \n",
       "0  1.000000  \n",
       "1  1.000000  \n",
       "2  0.974026  \n",
       "3  0.933333  \n",
       "4  1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We need to have some sort of label in order to figure out if a review is helpful or not helpful, so we'll need to define an\n",
    "#arbitrary ratio + \n",
    "a = df['helpful'][:]\n",
    "helpful = []\n",
    "notHelpful = []\n",
    "for i in a:\n",
    "    helpful.append(i[0])\n",
    "    notHelpful.append(i[1])\n",
    "df['helpUp'] = helpful\n",
    "df['helpDown'] = notHelpful\n",
    "df['hRatio'] = df.helpUp/df.helpDown\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185557"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['helpUp'][df.helpUp == 0].count()\n",
    "df['helpUp'][df.helpDown == 0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Subset the data\n",
    "Determining what constitutes a 'helpful' review is tough, and if we're going off ratios reviews where 1 out of 1 person found it helpful wil lbe considered very helpful even though it might not be. I arbitrarily decided that a review is more credible if at least 3 people voted it to be helpful. I then subsetted the dataframe for those reviews. \n",
    "\n",
    "After that, I created four classifiers for the data and assigned the column to the dataframe:\n",
    "* 0% - 25% is considered useless\n",
    "* 25% - 50% is considered unhelpful\n",
    "* 50% - 75% is considered moderarely helpful\n",
    "* 75% - 100% is considered helpful\n",
    "\n",
    "Lastly, I subsetted the first 10000 rows as the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove all 0 - 2 reviews\n",
    "df2 = df.loc[df.helpUp > 2]\n",
    "df2 = df2.reset_index(drop=True)\n",
    "#0-25% = useless, 25-50% is unhelpful, 50-75% is moderate,  75-100% is helpful\n",
    "senti = pd.Series(np.random.randn(len(df2.asin)))\n",
    "df2 = df2.assign(sentiment = senti.values)\n",
    "df2.loc[:,'sentiment'][df2['hRatio']<0.25] = 'useless'\n",
    "df2.loc[:,'sentiment'][(df2['hRatio']>0.25) & (df2['hRatio']<0.50)] = 'unhelpful'\n",
    "df2.loc[:,'sentiment'][(df2['hRatio']>0.50) & (df2['hRatio']<0.75)] = 'moderate'\n",
    "df2.loc[:,'sentiment'][(df2['hRatio']>0.75) & (df2['hRatio']<= 1)] = 'helpful'\n",
    "train = df2[0:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean the reviews \n",
    "Clean the reviews so they can be used for a bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liked quality lens built light lens discernable distortion anywhere magnified everything evenly without ripples distortion seen low cost magnifiers light nice touch easy use want pull lens bit focused close center look provides nice even coverage like brightness actually dimmness light focused leds lots brighter know seen also light focuses center field view lens close focused properly bottom line good value magnifier could made great better quality control btw feel honest effective reviews take place first hand experiences lacking online shopping always appreciated help received reviewers work hard return favor best hope found review helpful anything thought lacking unclear leave comment fix\n",
      "\n",
      " Cleaning and parsing the training set Amazon reviews...\n",
      "\n",
      "Review 1000 of 10000\n",
      "\n",
      "Review 2000 of 10000\n",
      "\n",
      "Review 3000 of 10000\n",
      "\n",
      "Review 4000 of 10000\n",
      "\n",
      "Review 5000 of 10000\n",
      "\n",
      "Review 6000 of 10000\n",
      "\n",
      "Review 7000 of 10000\n",
      "\n",
      "Review 8000 of 10000\n",
      "\n",
      "Review 9000 of 10000\n",
      "\n",
      "Review 10000 of 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Function to clean a review. \n",
    "#1. Use regex to remove all non letters\n",
    "#2. Lowercase all words and split the review into words\n",
    "#3. remove all \"stopwords\" from the review\n",
    "#4. Join back the final words into the cleaned review\n",
    "samp = train['reviewText'][0]\n",
    "def to_words(review):\n",
    "    letters = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    words = letters.lower().split()\n",
    "    good_words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "    return( \" \".join( good_words ))   \n",
    "\n",
    "clean_review = to_words( samp )\n",
    "print clean_review\n",
    "\n",
    "#Clean all the reviews and append the reviews to a list.\n",
    "print \"\\n Cleaning and parsing the training set Amazon reviews...\\n\"\n",
    "train_rvws = []\n",
    "num_rvws = train['reviewText'].size\n",
    "for i in xrange( 0, num_rvws ):\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_rvws )                                                                    \n",
    "    train_rvws.append( to_words( train[\"reviewText\"][i] ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the model\n",
    "In order to train the model, we will give the model certain words (features) to look for to classify the review. These words are chosen from the cleaned reviews.\n",
    "\n",
    "CountVectorizer is an object by scikit-learn used to create the features from text, and you can see the attributes can be modified to fit certain needs. fit_transform() trains the model and creates vectors from the reviews. We convert the vectors to numpy arrays for faster processing.\n",
    "\n",
    "Finally use RandomForestClassifier to create the model in an object called forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the features to train the decision tree using CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 1000) \n",
    "train_data_features = vectorizer.fit_transform(train_rvws)\n",
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'able', u'absolutely', u'absorption', u'accurate', u'acid', u'acids', u'acne', u'across', u'action', u'active', u'actually', u'add', u'added', u'addition', u'age', u'ago', u'aid', u'air', u'alcohol', u'allergic', u'allergies', u'allergy', u'almost', u'alone', u'along', u'already', u'also', u'alternative', u'although', u'always', u'amazing', u'amazon', u'amino', u'amount', u'another', u'anti', u'antibiotics', u'anxiety', u'anymore', u'anyone', u'anything', u'anyway', u'anywhere', u'applied', u'apply', u'area', u'areas', u'around', u'arrived', u'asleep', u'available', u'average', u'avoid', u'away', u'baby', u'back', u'bacteria', u'bad', u'bag', u'bar', u'bars', u'base', u'based', u'basically', u'bath', u'bathroom', u'batteries', u'battery', u'beard', u'become', u'bed', u'began', u'behind', u'believe', u'benefit', u'benefits', u'best', u'better', u'big', u'bit', u'black', u'blade', u'blades', u'blood', u'blue', u'body', u'bottle', u'bottles', u'bottom', u'bought', u'box', u'brain', u'brand', u'brands', u'braun', u'break', u'brush', u'brushes', u'brushing', u'burn', u'burning', u'buy', u'buying', u'calcium', u'call', u'called', u'calm', u'calories', u'came', u'cancer', u'candida', u'cane', u'cannot', u'cap', u'caps', u'capsule', u'capsules', u'car', u'care', u'careful', u'carry', u'case', u'cause', u'caused', u'causes', u'cells', u'certain', u'certainly', u'certified', u'chair', u'change', u'changed', u'charge', u'charger', u'cheap', u'cheaper', u'check', u'chelated', u'chemical', u'chemicals', u'children', u'chocolate', u'choice', u'cholesterol', u'chronic', u'citrate', u'claims', u'clean', u'cleaner', u'cleaning', u'clear', u'close', u'coconut', u'coffee', u'cold', u'color', u'com', u'combination', u'come', u'comes', u'comfortable', u'coming', u'common', u'company', u'compared', u'comparison', u'complete', u'completely', u'complex', u'condition', u'consider', u'contain', u'container', u'contains', u'content', u'continue', u'control', u'cool', u'cost', u'could', u'count', u'counter', u'couple', u'course', u'cover', u'cramps', u'cream', u'cup', u'cure', u'cushion', u'customer', u'cut', u'cuts', u'cutting', u'cycle', u'daily', u'damage', u'dark', u'date', u'daughter', u'day', u'days', u'deal', u'decided', u'deep', u'definitely', u'dental', u'dentist', u'depression', u'design', u'designed', u'device', u'diet', u'difference', u'different', u'difficult', u'digestive', u'directions', u'disappointed', u'discovered', u'disease', u'doctor', u'doctors', u'dog', u'done', u'dosage', u'dose', u'doses', u'double', u'dr', u'drink', u'drinking', u'drop', u'drops', u'drug', u'dry', u'due', u'ear', u'early', u'ease', u'easier', u'easily', u'easy', u'eat', u'eating', u'effect', u'effective', u'effects', u'either', u'electric', u'else', u'empty', u'end', u'energy', u'enjoy', u'enough', u'enteric', u'entire', u'enzymes', u'especially', u'essential', u'etc', u'even', u'evening', u'ever', u'every', u'everyone', u'everything', u'exactly', u'excellent', u'except', u'exercise', u'expect', u'expected', u'expensive', u'experience', u'experienced', u'extra', u'extract', u'extremely', u'eye', u'eyes', u'face', u'fact', u'fairly', u'fall', u'family', u'far', u'fast', u'faster', u'fat', u'favorite', u'feature', u'feel', u'feeling', u'feels', u'feet', u'felt', u'fiber', u'figured', u'finally', u'find', u'fine', u'fingers', u'first', u'fish', u'fit', u'five', u'flavor', u'floor', u'floss', u'foam', u'foil', u'follow', u'followed', u'following', u'food', u'foods', u'foot', u'forget', u'form', u'formula', u'found', u'four', u'free', u'fresh', u'friend', u'friends', u'front', u'fruit', u'full', u'function', u'gas', u'gave', u'gel', u'general', u'get', u'gets', u'getting', u'give', u'given', u'gives', u'giving', u'glad', u'glass', u'gloves', u'go', u'goes', u'going', u'gold', u'gone', u'good', u'got', u'gotten', u'grade', u'grams', u'great', u'green', u'growth', u'guess', u'gum', u'gums', u'hair', u'hairs', u'half', u'hand', u'handle', u'hands', u'happen', u'happy', u'hard', u'head', u'heads', u'healing', u'health', u'healthy', u'heard', u'heart', u'heat', u'heating', u'heavy', u'help', u'helped', u'helpful', u'helping', u'helps', u'herb', u'high', u'higher', u'highly', u'hold', u'home', u'hope', u'hoping', u'horrible', u'hot', u'hour', u'hours', u'house', u'however', u'huge', u'hurt', u'husband', u'ice', u'idea', u'immediately', u'immune', u'important', u'impressed', u'improved', u'improvement', u'inch', u'included', u'including', u'increase', u'inexpensive', u'infection', u'infections', u'information', u'ingredient', u'ingredients', u'inside', u'instead', u'instructions', u'iron', u'irritation', u'issue', u'issues', u'item', u'items', u'job', u'juice', u'keep', u'keeping', u'keeps', u'kept', u'kids', u'kind', u'kit', u'kitchen', u'knee', u'knees', u'knew', u'know', u'known', u'kosher', u'krill', u'label', u'large', u'larger', u'last', u'lasts', u'later', u'learned', u'least', u'leave', u'leaves', u'left', u'leg', u'legs', u'length', u'less', u'let', u'level', u'levels', u'life', u'light', u'like', u'liked', u'likely', u'line', u'liquid', u'list', u'listed', u'little', u'live', u'liver', u'local', u'long', u'longer', u'look', u'looked', u'looking', u'looks', u'lose', u'loss', u'lost', u'lot', u'lots', u'love', u'low', u'lower', u'machine', u'made', u'magnesium', u'main', u'major', u'make', u'makes', u'making', u'manual', u'manufacturer', u'many', u'market', u'massage', u'material', u'matter', u'may', u'maybe', u'mcg', u'meal', u'mean', u'means', u'medical', u'medication', u'medications', u'medicine', u'meds', u'melatonin', u'memory', u'mention', u'mentioned', u'mg', u'mgs', u'middle', u'might', u'mild', u'milk', u'mind', u'mine', u'minerals', u'minute', u'minutes', u'miracle', u'mix', u'mixed', u'model', u'money', u'monitor', u'month', u'months', u'mood', u'morning', u'mostly', u'mother', u'mouth', u'move', u'much', u'multi', u'multiple', u'muscle', u'muscles', u'must', u'nails', u'name', u'natural', u'naturals', u'nature', u'near', u'nearly', u'neck', u'need', u'needed', u'needs', u'negative', u'never', u'new', u'next', u'nice', u'night', u'non', u'none', u'norelco', u'normal', u'normally', u'nose', u'note', u'nothing', u'notice', u'noticeable', u'noticed', u'number', u'nutrition', u'odor', u'office', u'often', u'oh', u'oil', u'oils', u'ok', u'old', u'older', u'omega', u'one', u'ones', u'online', u'onto', u'open', u'opinion', u'oral', u'orange', u'order', u'ordered', u'organic', u'original', u'others', u'otherwise', u'outside', u'overall', u'oxide', u'oz', u'pack', u'package', u'packaging', u'pad', u'pads', u'paid', u'pain', u'painful', u'pair', u'panasonic', u'paper', u'part', u'particular', u'parts', u'past', u'pay', u'people', u'per', u'perfect', u'perfectly', u'perhaps', u'period', u'person', u'personal', u'pick', u'piece', u'pill', u'pillow', u'pills', u'place', u'plan', u'plastic', u'pleasant', u'please', u'pleased', u'plus', u'point', u'positive', u'possible', u'post', u'pounds', u'powder', u'power', u'pre', u'prefer', u'pregnant', u'prescription', u'pressure', u'pretty', u'prevent', u'previous', u'price', u'priced', u'probably', u'probiotics', u'problem', u'problems', u'process', u'product', u'products', u'properly', u'protein', u'provide', u'provides', u'pull', u'purchase', u'purchased', u'pure', u'purpose', u'put', u'putting', u'quality', u'quick', u'quickly', u'quite', u'rate', u'rated', u'rather', u'rating', u'raw', u'razor', u'razors', u'reach', u'read', u'reading', u'real', u'really', u'reason', u'reasons', u'received', u'recently', u'recommend', u'recommended', u'red', u'reduce', u'reduced', u'regular', u'regularly', u'relief', u'remember', u'remove', u'removed', u'replace', u'replacement', u'research', u'residue', u'rest', u'result', u'results', u'return', u'review', u'reviewer', u'reviewers', u'reviews', u'rid', u'right', u'rinse', u'roll', u'room', u'root', u'rubber', u'run', u'running', u'safe', u'said', u'salt', u'save', u'saw', u'say', u'says', u'scale', u'scent', u'seat', u'second', u'seconds', u'see', u'seed', u'seem', u'seemed', u'seems', u'seen', u'sensitive', u'sent', u'serious', u'service', u'serving', u'set', u'setting', u'several', u'severe', u'shake', u'shape', u'shave', u'shaver', u'shaving', u'shipping', u'short', u'show', u'shower', u'sick', u'side', u'silver', u'similar', u'simple', u'simply', u'since', u'single', u'sink', u'sinus', u'sit', u'site', u'sitting', u'six', u'size', u'skin', u'sleep', u'sleeping', u'slight', u'slightly', u'small', u'smaller', u'smell', u'smells', u'smooth', u'soap', u'soft', u'sold', u'solution', u'someone', u'something', u'sometimes', u'somewhat', u'son', u'sonicare', u'soon', u'sore', u'sort', u'source', u'soy', u'spend', u'spirulina', u'spot', u'spray', u'stains', u'stand', u'standard', u'star', u'stars', u'start', u'started', u'starting', u'stay', u'stick', u'still', u'stomach', u'stop', u'stopped', u'store', u'stores', u'straight', u'strap', u'strength', u'stress', u'strips', u'strong', u'studies', u'stuff', u'suffer', u'sugar', u'suggest', u'suggested', u'super', u'supplement', u'supplements', u'supply', u'support', u'supposed', u'sure', u'surface', u'surgery', u'surprised', u'swallow', u'sweet', u'switch', u'symptoms', u'system', u'tablet', u'tablets', u'take', u'taken', u'takes', u'taking', u'tape', u'taste', u'tastes', u'tea', u'teeth', u'tell', u'tend', u'term', u'terrible', u'test', u'tests', u'thank', u'thanks', u'thick', u'thin', u'thing', u'things', u'think', u'thinking', u'third', u'though', u'thought', u'three', u'throat', u'thyroid', u'tight', u'time', u'times', u'tiny', u'tip', u'tired', u'tissue', u'today', u'together', u'toilet', u'told', u'tongue', u'took', u'tooth', u'toothbrush', u'top', u'total', u'totally', u'touch', u'towel', u'travel', u'treat', u'treatment', u'tried', u'trimmer', u'trouble', u'true', u'truly', u'try', u'trying', u'tub', u'tube', u'turn', u'turned', u'twice', u'two', u'type', u'types', u'uncomfortable', u'unfortunately', u'unit', u'unless', u'unlike', u'update', u'upon', u'upset', u'us', u'use', u'used', u'useful', u'uses', u'using', u'usually', u'value', u'vanilla', u'various', u'vegetable', u'version', u'vinegar', u'vitamin', u'vitamins', u'wait', u'wake', u'walking', u'want', u'wanted', u'warm', u'wash', u'waste', u'watch', u'water', u'wax', u'way', u'wear', u'wearing', u'website', u'week', u'weeks', u'weight', u'well', u'went', u'wet', u'whatever', u'whether', u'whey', u'white', u'whole', u'wide', u'wife', u'wish', u'within', u'without', u'women', u'wonderful', u'work', u'worked', u'working', u'workout', u'works', u'world', u'worse', u'worth', u'would', u'wow', u'wrong', u'year', u'years', u'yeast', u'yes', u'yet', u'yogurt', u'zinc']\n"
     ]
    }
   ],
   "source": [
    "#See the bag of words and features\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print vocab\n",
    "\n",
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it appears in the training set\n",
    "# Uncomment if you want to print\n",
    "#for tag, count in zip(vocab, dist):\n",
    "#    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "forest = forest.fit( train_data_features, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat on the test dataset\n",
    "Here we repeat all the same steps on the test dataset and use the forest model on the features gotten from the test data. The ouput is then converted into a dictionary with the ASIN and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 10000\n",
      "\n",
      "Review 2000 of 10000\n",
      "\n",
      "Review 3000 of 10000\n",
      "\n",
      "Review 4000 of 10000\n",
      "\n",
      "Review 5000 of 10000\n",
      "\n",
      "Review 6000 of 10000\n",
      "\n",
      "Review 7000 of 10000\n",
      "\n",
      "Review 8000 of 10000\n",
      "\n",
      "Review 9000 of 10000\n",
      "\n",
      "Review 10000 of 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = df2[25000:35000]\n",
    "test.index = range(10000)\n",
    "test_rvws = []\n",
    "num_rvws = test['reviewText'].size\n",
    "for i in xrange(0, num_rvws):\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % ( i+1, num_rvws )                                                                    \n",
    "    test_rvws.append( to_words( test[\"reviewText\"][i] ))\n",
    "\n",
    "test_data_features = vectorizer.transform(test_rvws)\n",
    "test_data_features = test_data_features.toarray()\n",
    "result = forest.predict(test_data_features)\n",
    "output = pd.DataFrame( data={\"id\":test[\"asin\"], \"sentiment\":result} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test the accuracy\n",
    "See how the results of the test line up with the results of the model using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id sentiment\n",
      "0  B001OBZG6C   helpful\n",
      "1  B001OBZHGG   helpful\n",
      "2  B001OBZHGG   helpful\n",
      "3  B001OCEVAS   helpful\n",
      "4  B001OCEVAS   helpful\n",
      "         asin sentiment\n",
      "0  B001OBZG6C   helpful\n",
      "1  B001OBZHGG   helpful\n",
      "2  B001OBZHGG   helpful\n",
      "3  B001OCEVAS  moderate\n",
      "4  B001OCEVAS   helpful\n",
      "Model is 69.52% accurate\n"
     ]
    }
   ],
   "source": [
    "#confirm ASIN line up\n",
    "print output.head()\n",
    "print test[['asin','sentiment']].head()\n",
    "count = 0.0\n",
    "\n",
    "#loop through each row in the sentiment column and compare if they are equal, if so, add + 1 to the count\n",
    "for i in xrange(0,len(output)):\n",
    "    if test['sentiment'][i] == output['sentiment'][i]:\n",
    "        count += 1\n",
    "acc = 100*(count/len(output))\n",
    "print \"Model is {}% accurate\".format(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
